
@article{meinshausen_high-dimensional_2006,
	title = {High-dimensional graphs and variable selection with the Lasso},
	volume = {34},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-3/High-dimensional-graphs-and-variable-selection-with-the-Lasso/10.1214/009053606000000281.full},
	doi = {10.1214/009053606000000281},
	abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
	pages = {1436--1462},
	number = {3},
	journaltitle = {The Annals of Statistics},
	author = {Meinshausen, Nicolai and Bühlmann, Peter},
	urldate = {2023-11-07},
	date = {2006-06},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62F12, 62H20, 62J07, covariance selection, Gaussian graphical models, Linear regression, penalized regression},
	file = {Full Text PDF:/Users/jdomi/Zotero/storage/TAFCKSCW/Meinshausen and Bühlmann - 2006 - High-dimensional graphs and variable selection wit.pdf:application/pdf},
}

@software{augugliaro_cglasso_2023,
	title = {cglasso: Conditional Graphical {LASSO} for Gaussian Graphical Models with Censored and Missing Values},
	rights = {{GPL}-2 {\textbar} {GPL}-3 [expanded from: {GPL} (≥ 2)]},
	url = {https://cran.r-project.org/web/packages/cglasso/index.html},
	shorttitle = {cglasso},
	abstract = {Conditional graphical lasso estimator is an extension of the graphical lasso proposed to estimate the conditional dependence structure of a set of p response variables given q predictors. This package provides suitable extensions developed to study datasets with censored and/or missing values. Standard conditional graphical lasso is available as a special case. Furthermore, the package provides an integrated set of core routines for visualization, analysis, and simulation of datasets with censored and/or missing values drawn from a Gaussian graphical model. Details about the implemented models can be found in Augugliaro et al. (2023) {\textless}doi:10.18637/jss.v105.i01{\textgreater}, Augugliaro et al. (2020b) {\textless}doi:10.1007/s11222-020-09945-7{\textgreater}, Augugliaro et al. (2020a) {\textless}doi:10.1093/biostatistics/kxy043{\textgreater}, Yin et al. (2001) {\textless}doi:10.1214/11-{AOAS}494{\textgreater} and Stadler et al. (2012) {\textless}doi:10.1007/s11222-010-9219-7{\textgreater}.},
	version = {2.0.6},
	author = {Augugliaro, Luigi and Sottile, Gianluca and Wit, Ernst C. and Vinciotti, Veronica},
	urldate = {2023-11-07},
	date = {2023-01-17},
	keywords = {{MissingData}},
}

@software{friedman_glasso_2019,
	title = {glasso: Graphical Lasso: Estimation of Gaussian Graphical Models},
	rights = {{GPL}-2},
	url = {https://cran.r-project.org/web/packages/glasso/index.html},
	shorttitle = {glasso},
	abstract = {Estimation of a sparse inverse covariance matrix using a lasso (L1) penalty. Facilities are provided for estimates along a path of values for the regularization parameter.},
	version = {1.11},
	author = {Friedman, Jerome and Tibshirani, Trevor Hastie \{and\} Rob},
	urldate = {2023-11-07},
	date = {2019-10-01},
	keywords = {Psychometrics},
}

@article{stadler_missing_2010,
	title = {Missing values: sparse inverse covariance estimation and an extension to sparse regression},
	volume = {22},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-010-9219-7},
	doi = {10.1007/s11222-010-9219-7},
	shorttitle = {Missing values},
	abstract = {We propose an 1-regularized likelihood method for estimating the inverse covariance matrix in the highdimensional multivariate normal model in presence of missing data. Our method is based on the assumption that the data are missing at random ({MAR}) which entails also the completely missing at random case. The implementation of the method is non-trivial as the observed negative loglikelihood generally is a complicated and non-convex function. We propose an efﬁcient {EM} algorithm for optimization with provable numerical convergence properties. Furthermore, we extend the methodology to handle missing values in a sparse regression context. We demonstrate both methods on simulated and real data.},
	pages = {219--235},
	number = {1},
	journaltitle = {Statistics and Computing},
	shortjournal = {Stat Comput},
	author = {Städler, Nicolas and Bühlmann, Peter},
	urldate = {2023-11-07},
	date = {2010},
	langid = {english},
	file = {Städler and Bühlmann - 2012 - Missing values sparse inverse covariance estimati.pdf:/Users/jdomi/Zotero/storage/AYSY9F23/Städler and Bühlmann - 2012 - Missing values sparse inverse covariance estimati.pdf:application/pdf},
}

@software{zheng_gi-joe_2023,
	title = {{GI}-{JOE}: Graph Inference when Joint Observations are Erose},
	url = {https://github.com/Lili-Zheng-stat/GI-JOE},
	shorttitle = {{GI}-{JOE}},
	author = {Zheng, Lili},
	urldate = {2023-11-07},
	date = {2023-03-31},
}

@misc{zheng_graphical_2023,
	title = {Graphical Model Inference with Erosely Measured Data},
	url = {http://arxiv.org/abs/2210.11625},
	doi = {10.48550/arXiv.2210.11625},
	abstract = {In this paper, we investigate the Gaussian graphical model inference problem in a novel setting that we call erose measurements, referring to irregularly measured or observed data. For graphs, this results in different node pairs having vastly different sample sizes which frequently arises in data integration, genomics, neuroscience, and sensor networks. Existing works characterize the graph selection performance using the minimum pairwise sample size, which provides little insights for erosely measured data, and no existing inference method is applicable. We aim to fill in this gap by proposing the first inference method that characterizes the different uncertainty levels over the graph caused by the erose measurements, named {GI}-{JOE} (Graph Inference when Joint Observations are Erose). Specifically, we develop an edge-wise inference method and an affiliated {FDR} control procedure, where the variance of each edge depends on the sample sizes associated with corresponding neighbors. We prove statistical validity under erose measurements, thanks to careful localized edge-wise analysis and disentangling the dependencies across the graph. Finally, through simulation studies and a real neuroscience data example, we demonstrate the advantages of our inference methods for graph selection from erosely measured data.},
	number = {{arXiv}:2210.11625},
	publisher = {{arXiv}},
	author = {Zheng, Lili and Allen, Genevera I.},
	urldate = {2023-11-07},
	date = {2023-05-14},
	eprinttype = {arxiv},
	eprint = {2210.11625 [math, stat]},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/jdomi/Zotero/storage/8AYTETIS/Zheng and Allen - 2023 - Graphical Model Inference with Erosely Measured Da.pdf:application/pdf;arXiv.org Snapshot:/Users/jdomi/Zotero/storage/HDVEVXQ8/2210.html:text/html},
}

@article{chen_selection_2015,
	title = {Selection and estimation for mixed graphical models},
	volume = {102},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/asu051},
	doi = {10.1093/biomet/asu051},
	abstract = {We consider the problem of estimating the parameters in a pairwise graphical model in which the distribution of each node, conditioned on the others, may have a different exponential family form. We identify restrictions on the parameter space required for the existence of a well-defined joint density, and establish the consistency of the neighbourhood selection approach for graph reconstruction in high dimensions when the true underlying graph is sparse. Motivated by our theoretical results, we investigate the selection of edges between nodes whose conditional distributions take different parametric forms, and show that efficiency can be gained if edge estimates obtained from the regressions of particular nodes are used to reconstruct the graph. These results are illustrated with examples of Gaussian, Bernoulli, Poisson and exponential distributions. Our theoretical findings are corroborated by evidence from simulation studies.},
	pages = {47--64},
	number = {1},
	journaltitle = {Biometrika},
	shortjournal = {Biometrika},
	author = {Chen, Shizhe and Witten, Daniela M. and Shojaie, Ali},
	urldate = {2023-11-07},
	date = {2015-03-01},
	file = {Accepted Version:/Users/jdomi/Zotero/storage/D2YURGMJ/Chen et al. - 2015 - Selection and estimation for mixed graphical model.pdf:application/pdf;Snapshot:/Users/jdomi/Zotero/storage/EECAMIB6/228946.html:text/html},
}

@article{friedman_sparse_2008,
	title = {Sparse inverse covariance estimation with the graphical lasso},
	volume = {9},
	issn = {1465-4644},
	url = {https://doi.org/10.1093/biostatistics/kxm045},
	doi = {10.1093/biostatistics/kxm045},
	abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm—the graphical lasso—that is remarkably fast: It solves a 1000-node problem (∼500000 parameters) in at most a minute and is 30–4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and Bühlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
	pages = {432--441},
	number = {3},
	journaltitle = {Biostatistics},
	shortjournal = {Biostatistics},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	urldate = {2023-11-07},
	date = {2008-07-01},
	file = {Full Text PDF:/Users/jdomi/Zotero/storage/S3B6QTSV/Friedman et al. - 2008 - Sparse inverse covariance estimation with the grap.pdf:application/pdf;Snapshot:/Users/jdomi/Zotero/storage/C82PGNK5/224260.html:text/html},
}

@article{meinshausen_note_2008,
	title = {A note on the Lasso for Gaussian graphical model selection},
	volume = {78},
	issn = {0167-7152},
	url = {https://www.sciencedirect.com/science/article/pii/S0167715207002945},
	doi = {10.1016/j.spl.2007.09.014},
	abstract = {Inspired by the success of the Lasso for regression analysis, it seems attractive to estimate the graph of a multivariate normal distribution by ℓ1-norm penalized likelihood maximization. We examine some properties of the estimator and show that care has to be taken with interpretation of results as the estimator is not consistent for some graphs.},
	pages = {880--884},
	number = {7},
	journaltitle = {Statistics \& Probability Letters},
	shortjournal = {Statistics \& Probability Letters},
	author = {Meinshausen, Nicolai},
	urldate = {2023-11-07},
	date = {2008-05-01},
	file = {ScienceDirect Snapshot:/Users/jdomi/Zotero/storage/L3DSSSJL/S0167715207002945.html:text/html},
}

@article{park_estimating_2021,
	title = {Estimating high-dimensional covariance and precision matrices under general missing dependence},
	volume = {15},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-15/issue-2/Estimating-high-dimensional-covariance-and-precision-matrices-under-general-missing/10.1214/21-EJS1892.full},
	doi = {10.1214/21-EJS1892},
	abstract = {A sample covariance matrix S of completely observed data is the key statistic in a large variety of multivariate statistical procedures, such as structured covariance/precision matrix estimation, principal component analysis, and testing of equality of mean vectors. However, when the data are partially observed, the sample covariance matrix from the available data is biased and does not provide valid multivariate procedures. To correct the bias, a simple adjustment method called inverse probability weighting ({IPW}) has been used in previous research, yielding the {IPW} estimator. The estimator can play the role of S in the missing data context, thus replacing S in off-the-shelf multivariate procedures such as the graphical lasso algorithm. However, theoretical properties (e.g. concentration) of the {IPW} estimator have been only established in earlier work under very simple missing structures; every variable of each sample is independently subject to missingness with equal probability. We investigate the deviation of the {IPW} estimator when observations are partially observed under general missing dependency. We prove the optimal convergence rate Op( logp∕n) of the {IPW} estimator based on the element-wise maximum norm, even when two unrealistic assumptions (known mean and/or missing probabilities) frequently assumed to be known in the past work are relaxed. The optimal rate is especially crucial in estimating a precision matrix, because of the “meta-theorem” [26] that claims the rate of the {IPW} estimator governs that of the resulting precision matrix estimator. In the simulation study, we discuss one of practically important issues, non-positive semi-definiteness of the {IPW} estimator, and compare the estimator with imputation methods.},
	pages = {4868--4915},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	author = {Park, Seongoh and Wang, Xinlei and Lim, Johan},
	urldate = {2023-11-07},
	date = {2021-01},
	note = {Publisher: Institute of Mathematical Statistics and Bernoulli Society},
	keywords = {60E15, 62H12, convergence rate, Covariance matrix, dependent missing structure, element-wise maximum norm, inverse probability weighting},
	file = {Full Text PDF:/Users/jdomi/Zotero/storage/MFKXKUJH/Park et al. - 2021 - Estimating high-dimensional covariance and precisi.pdf:application/pdf},
}

@article{kolar_estimating_2012,
	title = {Estimating Sparse Precision Matrices from Data with Missing Values},
	abstract = {We study a simple two step procedure for estimating sparse precision matrices from data with missing values, which is tractable in high-dimensions and does not require imputation of the missing values. We provide rates of convergence for this estimator in the spectral norm, Frobenius norm and element-wise ∞ norm. Simulation studies show that this estimator compares favorably with the {EM} algorithm. Our results have important practical consequences as they show that standard tools for estimating sparse precision matrices can be used when data contains missing values, without resorting to the iterative {EM} algorithm that can be slow to converge in practice for large problems.},
	journaltitle = {Proceedings of the 29 th International Conference on Machine Learning},
	author = {Kolar, Mladen and Xing, Eric P},
	date = {2012},
	langid = {english},
	file = {Kolar and Xing - Estimating Sparse Precision Matrices from Data wit.pdf:/Users/jdomi/Zotero/storage/883M4WGW/Kolar and Xing - Estimating Sparse Precision Matrices from Data wit.pdf:application/pdf},
}
